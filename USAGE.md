# WhisperPy: Audio Transcription with Speaker Diarization

A powerful CLI tool that combines OpenAI Whisper for transcription with pyannote.audio for speaker diarization, providing LLM-friendly output.

## üöÄ Quick Start

### 1. Basic Installation

```bash
pip install -e .
```

This installs the basic transcription functionality using OpenAI Whisper.

### 2. Speaker Diarization Setup (Optional)

For speaker identification features, install additional dependencies:

```bash
# Install dependencies (requires cmake)
sudo apt install cmake  # Ubuntu/Debian
# or
brew install cmake      # macOS
# or
conda install cmake     # Conda

# Install with diarization support
pip install -e .[diarization]
```

Set up your HuggingFace token:

```bash
# Get token from: https://huggingface.co/settings/tokens
whipy set-token YOUR_HUGGINGFACE_TOKEN
```

## üìñ Usage

### Basic Commands

```bash
# Simple transcription (no speaker identification)
whipy transcribe audio.wav --no-diarization

# With speaker diarization (requires HF token)
whipy transcribe audio.wav

# Use different Whisper model
whipy transcribe audio.wav -m large

# Specify output format and file
whipy transcribe audio.wav -f txt -o transcript.txt

# Verbose output
whipy transcribe audio.wav -v
```

### Complete Options

```
Usage: whipy transcribe [OPTIONS] AUDIO_FILE

Options:
  -m, --model [tiny|base|small|medium|large|large-v2|large-v3]
                                  Whisper model to use (default: base)
  -o, --output PATH               Output file path 
  -l, --language TEXT             Language code (auto-detect if not specified)
  --no-diarization                Skip speaker diarization
  -f, --format [json|txt]         Output format (default: json)
  -v, --verbose                   Verbose output
```

## üìä Output Formats

### JSON Format (LLM-Friendly)

The default JSON output is specifically designed for LLM processing:

```json
{
  "metadata": {
    "total_duration_seconds": 45.6,
    "total_duration_formatted": "00:45",
    "num_speakers": 2,
    "num_segments": 8
  },
  "speakers": {
    "SPEAKER_00": {
      "total_segments": 4,
      "segments": [...]
    }
  },
  "conversation": [
    {
      "timestamp": "00:00",
      "speaker": "SPEAKER_00",
      "text": "Hello, welcome to our meeting."
    }
  ],
  "full_transcript": "Complete transcript..."
}
```

### TXT Format (Human-Readable)

```
=== TRANSCRIPTION SUMMARY ===
Duration: 00:45
Speakers detected: 2
Segments: 8

=== CONVERSATION ===
[00:00] SPEAKER_00: Hello, welcome to our meeting.
[00:04] SPEAKER_01: Thank you for having me.
...
```

## üéØ LLM Integration Benefits

The JSON output format is optimized for LLM processing with:

- **Structured data**: Easy to parse and analyze
- **Speaker separation**: Clear identification of who said what
- **Timeline information**: Precise timestamps for temporal analysis
- **Metadata**: Context about the conversation
- **Multiple views**: Conversation flow, speaker-grouped segments, full transcript

Perfect for:
- Meeting summarization
- Conversation analysis
- Content extraction
- Speaker sentiment analysis
- Action item identification

## üîß Technical Details

### Architecture

1. **Audio Input** ‚Üí **Whisper ASR** ‚Üí **Text Segments**
2. **Audio Input** ‚Üí **pyannote.audio** ‚Üí **Speaker Segments**  
3. **Segment Matching** ‚Üí **LLM-Friendly Output**

### Dependencies

- **Core**: openai-whisper, click
- **Diarization**: pyannote.audio, torch, torchaudio
- **System**: cmake (for building pyannote dependencies)

### Supported Formats

Audio: WAV, MP3, M4A, FLAC, MP4, and all FFmpeg-supported formats

## üõ†Ô∏è Development

```bash
# Clone and install in development mode
git clone <repo>
cd whisperpy
pip install -e .

# Install with diarization
pip install -e .[diarization]

# Run tests
pytest
```

## üìù Examples

See `example_output.json` for a sample of the LLM-friendly output format.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

## üìÑ License

MIT License - see LICENSE file for details.
